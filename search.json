[
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "Articles",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nOptimizing Pandas\n\n\n\n\n\n\n\ndata science\n\n\ndata engineering\n\n\n \n\n\n\n\nDec 28, 2023\n\n\nClaudia L√≥pez\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nCoaching\n\n\n\n\n\n\n\ncoaching\n\n\nonboarding\n\n\n \n\n\n\n\nDec 18, 2023\n\n\nClaudia L√≥pez\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nOptimizing Pandas DataFrames\n\n\nFilter first!\n\n\n\n\ndata science\n\n\n \n\n\n\n\nDec 28, 2022\n\n\n5 min\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Claudia L√≥pez",
    "section": "",
    "text": "üí´ Hi there! I am Claudia L√≥pez, a Senior Data Engineer with a degree in Computer Science. I possess strong experience in Software Engineering and I am committed to continuous learning and staying up-to-date.\nI created this blog to share my knowledge, findings and experiences about Software Engineering, Data Engineering, Machine Learning, and other interesting aspects of my professional journey."
  },
  {
    "objectID": "posts/data_engineering/Optimizing_Pandas_DataFrames.html",
    "href": "posts/data_engineering/Optimizing_Pandas_DataFrames.html",
    "title": "Optimizing Pandas DataFrames",
    "section": "",
    "text": "Created by: ‚≠ê Claudia L√≥pez ‚≠ê\nWhen chaining multiple operations it is worthwhile to think about which operations to execute first in order to optimize the sentence. Filter steps should be executed as early as possible\nIt is always recommended to filter the data where the data lives, for example, in other words in BigQuery, but if this is not the case, you should filter your dataframe as soon as possible to only work with the data you need, thus optimizing your operations.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport time\n\ntitanic_data = pd.read_csv('test.csv')\npassenger_id = 895\ntitanic_data\n\n\n  \n    \n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\nSpector, Mr. Woolf\nmale\nNaN\n0\n0\nA.5. 3236\n8.0500\nNaN\nS\n\n\n414\n1306\n1\nOliva y Ocana, Dona. Fermina\nfemale\n39.0\n0\n0\nPC 17758\n108.9000\nC105\nC\n\n\n415\n1307\n3\nSaether, Mr. Simon Sivertsen\nmale\n38.5\n0\n0\nSOTON/O.Q. 3101262\n7.2500\nNaN\nS\n\n\n416\n1308\n3\nWare, Mr. Frederick\nmale\nNaN\n0\n0\n359309\n8.0500\nNaN\nS\n\n\n417\n1309\n3\nPeter, Master. Michael J\nmale\nNaN\n1\n1\n2668\n22.3583\nNaN\nC\n\n\n\n\n\n418 rows √ó 11 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\nPandas provides a lot of methods for data selection, below you can review some methods.\n\n\nIndexing is the easier way of filtering the data where the condition expression creates a Boolean series, and we can use it to filter the DataFrame.\n\nstart = time.time()\n\n#Filter using []\npassengers_by_ticket_index = titanic_data[(titanic_data['PassengerId'] == passenger_id)]\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 1.646280288696289 ms\n\n\n\n\n\nThis is a much cleaner and easier way to filter rows. Also, query() supports much more complicated conditional expressions and is faster than using [].\n\nstart = time.time()\n\n#Filter using query\npassengers_by_ticket_query = titanic_data.query('PassengerId == @passenger_id')\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 6.360054016113281 ms\n\n\n\n\n\nThe eval() function in Pandas uses string expressions to efficiently compute operations using DataFrame.\n\nstart = time.time()\n\n#Filter using eval\npassengers_by_ticket_eval = titanic_data[titanic_data.eval('PassengerId == @passenger_id')]\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 4.781246185302734 ms\n\n\n\n\n‚úÖ The traditional method [] is faster for smaller arrays.\n‚úÖ The benefit of eval and query is mainly in the saved memory, and the sometimes cleaner syntax they offer.\n‚úÖ The advantages of eval and query lies in humongous dataset.\n‚úÖ It is recommended to use eval or query when you work with a lot of data.\nüëÄ Optimizing the eval(), query(), [] filter operations would not necessarily guarantee performance improvement because it‚Äôs a multivariate equation.\n\n\n\n\n\nHere, there are some strategies and properties useful to lookup.\n\n# Variables\nposition = 3\ncolumn = \"Ticket\"\n\n\n\nPandas has optimized operations based on indices whereby It is recommended to use an index in dataframes to allow for faster lookup.\nSet the DataFrame index (row labels) using one or more existing columns or arrays (of the correct length). The index can replace the existing index or expand on it.\n\n# 1. We identify PassengerId as a candidate variables to use as index\ntitanic_data_indexed = titanic_data.set_index(\"PassengerId\", drop=False, inplace=False)\n\nstart = time.time()\n\n#2. Filtering a dataframe using PassengerId column\npassengers_by_ticket_eval = titanic_data_indexed[titanic_data_indexed.eval('PassengerId == @passenger_id')]\n\n#3. Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 4.584312438964844 ms\n\n\n\n\n\nWhen we need to retrieve a single value from a dataframe it‚Äôs recommended to use .at[] because is faster than using .loc[].\n\n\nThe .loc property of the DataFrame object allows the return of specified rows and/or columns from that DataFrame.\ndf.loc[rows,columns]\nNote: .loc is not a method, it is a property indexed via square brackets.\n\nstart = time.time()\npassenger = titanic_data.loc[position, column]\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 0.2779960632324219 ms\n\n\n\n\n\nAccess a single value for a row/column label pair.\nThis method works in a similar way to Pandas .loc[] but .at[] is used to return an only single value that‚Äôs because is faster.\n\nstart = time.time()\npassenger = titanic_data.at[position, column]\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 0.2944469451904297 ms\n\n\n\n\n\n\nVectorization is the process of executing operations on entire arrays. Similarly to NumPy.\nIt is recommended to avoid for loops when working with dataframes, because read and write operations are expensive. When looping is unavoidable, use native NumPy, or .map() for simple operations.\n###Verify Memory Usage\nEvery time when you work with a dataframe verify the memory usage, to achieve this you can use the functions: info() or memory_usage().\n\n\nShow a concise summary of a DataFrame.\n\ntitanic_data.info(verbose=True)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n\n\n\n\n\nThis function return the memory usage of each column in bytes.\n\ntitanic_data.memory_usage(index=False, deep=True)\n\nPassengerId     3344\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n\n\n\nWhen the dataset is read using Pandas read function like read_csv or read_excel, Pandas decides the data type and loads it into RAM. Normally for integer values Pandas assign int64, float values are assigned float64, and string values are assigned as objects, The problem here is that using an int64 takes up more memory compared to int8 (8 times more).\nThe idea is to downgrade the datatype reviewing el max and min value of a column and choose which is the correct data type for a specific column\nVisit Data types in Python\n\n\n\n# 1. Get info about the dataframe:\ntitanic_data.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n\n\n\n# 2. Show memory usage for the PassengerId column: 3344 bytes\ntitanic_data.memory_usage(index=False, deep=True)\n\nPassengerId     3344\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n#3. Get the Max and Min value for PassengerId column and decide the best datatype:\nmin_value = titanic_data[\"PassengerId\"].min()\nmax_value = titanic_data[\"PassengerId\"].max()\nprint(f\"Min Value: {min_value} - Max Value: {max_value}\")\n\nMin Value: 892 - Max Value: 1309\n\n\n\n\n\n‚ñ∂ The PassengerId column has values between 892 to 1309.\n‚ñ∂ This range does not contain negative numbers.\n‚ñ∂ Pandas assigned int64 to this column, but the range of int64 is Integer (-9223372036854775808 to 9223372036854775807):\n\nüî¥ It‚Äôs a wide range.\nüî¥ Allows negative numbers.\nüü¢ We can review the range of the different data types in the above table and choose the best range.\nüü¢ So, we finally decide to use uint16, but why is it the best option?\n\n‚úî range of uint16 is: Unsigned integer (0 to 65535)\n‚úî The range is enough to contain the values for the PassengerId Column.\n‚úî We only need a positive number\n\n\n\n\n#4 . Set PassengerId column to uint16 datatype:\ntitanic_data[\"PassengerId\"] = titanic_data[\"PassengerId\"].astype(\"uint16\")\n\n\n# 5. Show memory usage for the PassengerId column again:\ntitanic_data.memory_usage(index=False, deep=True)\n# PassengerId has reduced from to 3344 bytes 836 bytes\n\nPassengerId      836\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n# 6. Get info again:\ntitanic_data.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    uint16 \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(3), object(5), uint16(1)\nmemory usage: 33.6+ KB\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ Filter steps should be executed as early as possible.\n‚úÖ Filter for a single value, .at is a good choice.\n‚úÖ The method [] is faster for smaller arrays.\n‚úÖ Verify the memory usage with memory_usage method\n‚úÖ Downgrade the datatype reviewing el max and min value of a column and choose which is the correct data type for a specific column.\n‚úÖ Using an index in dataframes to allow for faster lookup.\n‚ùå Try to avoid for loops, but if you can‚Äôt avoid them, use .map()."
  },
  {
    "objectID": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#precondition-getting-data",
    "href": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#precondition-getting-data",
    "title": "Optimizing Pandas DataFrames",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport time\n\ntitanic_data = pd.read_csv('test.csv')\npassenger_id = 895\ntitanic_data\n\n\n  \n    \n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\nSpector, Mr. Woolf\nmale\nNaN\n0\n0\nA.5. 3236\n8.0500\nNaN\nS\n\n\n414\n1306\n1\nOliva y Ocana, Dona. Fermina\nfemale\n39.0\n0\n0\nPC 17758\n108.9000\nC105\nC\n\n\n415\n1307\n3\nSaether, Mr. Simon Sivertsen\nmale\n38.5\n0\n0\nSOTON/O.Q. 3101262\n7.2500\nNaN\nS\n\n\n416\n1308\n3\nWare, Mr. Frederick\nmale\nNaN\n0\n0\n359309\n8.0500\nNaN\nS\n\n\n417\n1309\n3\nPeter, Master. Michael J\nmale\nNaN\n1\n1\n2668\n22.3583\nNaN\nC\n\n\n\n\n\n418 rows √ó 11 columns"
  },
  {
    "objectID": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#filtering-methods",
    "href": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#filtering-methods",
    "title": "Optimizing Pandas DataFrames",
    "section": "",
    "text": "Pandas provides a lot of methods for data selection, below you can review some methods.\n\n\nIndexing is the easier way of filtering the data where the condition expression creates a Boolean series, and we can use it to filter the DataFrame.\n\nstart = time.time()\n\n#Filter using []\npassengers_by_ticket_index = titanic_data[(titanic_data['PassengerId'] == passenger_id)]\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 1.646280288696289 ms\n\n\n\n\n\nThis is a much cleaner and easier way to filter rows. Also, query() supports much more complicated conditional expressions and is faster than using [].\n\nstart = time.time()\n\n#Filter using query\npassengers_by_ticket_query = titanic_data.query('PassengerId == @passenger_id')\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 6.360054016113281 ms\n\n\n\n\n\nThe eval() function in Pandas uses string expressions to efficiently compute operations using DataFrame.\n\nstart = time.time()\n\n#Filter using eval\npassengers_by_ticket_eval = titanic_data[titanic_data.eval('PassengerId == @passenger_id')]\n\n# Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 4.781246185302734 ms\n\n\n\n\n‚úÖ The traditional method [] is faster for smaller arrays.\n‚úÖ The benefit of eval and query is mainly in the saved memory, and the sometimes cleaner syntax they offer.\n‚úÖ The advantages of eval and query lies in humongous dataset.\n‚úÖ It is recommended to use eval or query when you work with a lot of data.\nüëÄ Optimizing the eval(), query(), [] filter operations would not necessarily guarantee performance improvement because it‚Äôs a multivariate equation."
  },
  {
    "objectID": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#recommendatios-for-faster-lookup",
    "href": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#recommendatios-for-faster-lookup",
    "title": "Optimizing Pandas DataFrames",
    "section": "",
    "text": "Here, there are some strategies and properties useful to lookup.\n\n# Variables\nposition = 3\ncolumn = \"Ticket\"\n\n\n\nPandas has optimized operations based on indices whereby It is recommended to use an index in dataframes to allow for faster lookup.\nSet the DataFrame index (row labels) using one or more existing columns or arrays (of the correct length). The index can replace the existing index or expand on it.\n\n# 1. We identify PassengerId as a candidate variables to use as index\ntitanic_data_indexed = titanic_data.set_index(\"PassengerId\", drop=False, inplace=False)\n\nstart = time.time()\n\n#2. Filtering a dataframe using PassengerId column\npassengers_by_ticket_eval = titanic_data_indexed[titanic_data_indexed.eval('PassengerId == @passenger_id')]\n\n#3. Duration time\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 4.584312438964844 ms\n\n\n\n\n\nWhen we need to retrieve a single value from a dataframe it‚Äôs recommended to use .at[] because is faster than using .loc[].\n\n\nThe .loc property of the DataFrame object allows the return of specified rows and/or columns from that DataFrame.\ndf.loc[rows,columns]\nNote: .loc is not a method, it is a property indexed via square brackets.\n\nstart = time.time()\npassenger = titanic_data.loc[position, column]\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 0.2779960632324219 ms\n\n\n\n\n\nAccess a single value for a row/column label pair.\nThis method works in a similar way to Pandas .loc[] but .at[] is used to return an only single value that‚Äôs because is faster.\n\nstart = time.time()\npassenger = titanic_data.at[position, column]\nprint(f\"time : {(time.time() - start) * 1000} ms\")\n\ntime : 0.2944469451904297 ms\n\n\n\n\n\n\nVectorization is the process of executing operations on entire arrays. Similarly to NumPy.\nIt is recommended to avoid for loops when working with dataframes, because read and write operations are expensive. When looping is unavoidable, use native NumPy, or .map() for simple operations.\n###Verify Memory Usage\nEvery time when you work with a dataframe verify the memory usage, to achieve this you can use the functions: info() or memory_usage().\n\n\nShow a concise summary of a DataFrame.\n\ntitanic_data.info(verbose=True)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n\n\n\n\n\nThis function return the memory usage of each column in bytes.\n\ntitanic_data.memory_usage(index=False, deep=True)\n\nPassengerId     3344\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n\n\n\nWhen the dataset is read using Pandas read function like read_csv or read_excel, Pandas decides the data type and loads it into RAM. Normally for integer values Pandas assign int64, float values are assigned float64, and string values are assigned as objects, The problem here is that using an int64 takes up more memory compared to int8 (8 times more).\nThe idea is to downgrade the datatype reviewing el max and min value of a column and choose which is the correct data type for a specific column\nVisit Data types in Python\n\n\n\n# 1. Get info about the dataframe:\ntitanic_data.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n\n\n\n# 2. Show memory usage for the PassengerId column: 3344 bytes\ntitanic_data.memory_usage(index=False, deep=True)\n\nPassengerId     3344\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n#3. Get the Max and Min value for PassengerId column and decide the best datatype:\nmin_value = titanic_data[\"PassengerId\"].min()\nmax_value = titanic_data[\"PassengerId\"].max()\nprint(f\"Min Value: {min_value} - Max Value: {max_value}\")\n\nMin Value: 892 - Max Value: 1309\n\n\n\n\n\n‚ñ∂ The PassengerId column has values between 892 to 1309.\n‚ñ∂ This range does not contain negative numbers.\n‚ñ∂ Pandas assigned int64 to this column, but the range of int64 is Integer (-9223372036854775808 to 9223372036854775807):\n\nüî¥ It‚Äôs a wide range.\nüî¥ Allows negative numbers.\nüü¢ We can review the range of the different data types in the above table and choose the best range.\nüü¢ So, we finally decide to use uint16, but why is it the best option?\n\n‚úî range of uint16 is: Unsigned integer (0 to 65535)\n‚úî The range is enough to contain the values for the PassengerId Column.\n‚úî We only need a positive number\n\n\n\n\n#4 . Set PassengerId column to uint16 datatype:\ntitanic_data[\"PassengerId\"] = titanic_data[\"PassengerId\"].astype(\"uint16\")\n\n\n# 5. Show memory usage for the PassengerId column again:\ntitanic_data.memory_usage(index=False, deep=True)\n# PassengerId has reduced from to 3344 bytes 836 bytes\n\nPassengerId      836\nPclass          3344\nName           35314\nSex            25802\nAge             3344\nSibSp           3344\nParch           3344\nTicket         26700\nFare            3344\nCabin          16022\nEmbarked       24244\ndtype: int64\n\n\n\n# 6. Get info again:\ntitanic_data.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    uint16 \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(3), object(5), uint16(1)\nmemory usage: 33.6+ KB"
  },
  {
    "objectID": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#summary",
    "href": "posts/data_engineering/Optimizing_Pandas_DataFrames.html#summary",
    "title": "Optimizing Pandas DataFrames",
    "section": "",
    "text": "‚úÖ Filter steps should be executed as early as possible.\n‚úÖ Filter for a single value, .at is a good choice.\n‚úÖ The method [] is faster for smaller arrays.\n‚úÖ Verify the memory usage with memory_usage method\n‚úÖ Downgrade the datatype reviewing el max and min value of a column and choose which is the correct data type for a specific column.\n‚úÖ Using an index in dataframes to allow for faster lookup.\n‚ùå Try to avoid for loops, but if you can‚Äôt avoid them, use .map()."
  },
  {
    "objectID": "posts/software_engineering/coaching.html",
    "href": "posts/software_engineering/coaching.html",
    "title": "Coaching",
    "section": "",
    "text": "This is the article"
  },
  {
    "objectID": "posts/data_engineering/optimizing_pandas.html",
    "href": "posts/data_engineering/optimizing_pandas.html",
    "title": "Optimizing Pandas",
    "section": "",
    "text": "This is the article"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Claudia L√≥pez",
    "section": "",
    "text": "Hi there! I am Claudia L√≥pez, a Senior Data Engineer with a degree in Computer Science. I possess strong experience in Software Engineering and I am committed to continuous learning and staying up-to-date.\nI created this blog to share my knowledge, findings and experiences about Software Engineering, Data Engineering, Machine Learning, and other interesting aspects of my professional journey."
  }
]